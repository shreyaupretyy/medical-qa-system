# GPU-Accelerated Medical AI Dependencies
# For PubMedBERT + PMCLLama with GPU acceleration

# Core Python Dependencies
python-dotenv==1.0.0

# LangChain Integration (wrappers only - no behavioral changes)
langchain==0.1.0
langchain-community==0.0.13
langgraph==0.0.20

# GPU-Accelerated PyTorch (CUDA 12.1 compatible)
# Note: Install based on your CUDA version
# For CUDA 12.1: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
# For CUDA 11.8: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
# IMPORTANT: PubMedBERT requires torch>=2.6.0 due to security vulnerability (CVE-2025-32434)
# If using older torch, system will fallback to all-MiniLM-L6-v2
torch>=2.6.0
torchvision>=0.19.0
torchaudio>=2.6.0

# Vector Database and Embeddings (GPU-enabled)
faiss-gpu>=1.7.4  # GPU-accelerated FAISS
sentence-transformers>=2.2.0  # For PubMedBERT embeddings
transformers>=4.30.0  # For PubMedBERT and PMCLLama models

# GPU Optimization Libraries
accelerate>=0.20.0  # For model parallelism and optimization
bitsandbytes>=0.40.0  # For 4-bit quantization (PMCLLama)
xformers>=0.0.20  # For attention optimization (optional but recommended)

# Document Processing
PyPDF2==3.0.1
pypdf==3.17.4

# Text Processing
rank-bm25==0.2.2

# Data Validation
pydantic==2.5.3

# Evaluation Metrics
scikit-learn==1.3.2
rouge-score==0.1.2

# Testing
pytest==7.4.3
pytest-cov==4.1.0

# Data Handling
pandas==2.1.4
numpy==1.26.2

# Visualization
matplotlib==3.8.2
seaborn==0.13.0

# API (Optional)
fastapi==0.108.0
uvicorn==0.25.0

# Utilities
tqdm==4.66.1
requests==2.31.0
pyyaml==6.0.1

# Logging
colorlog==6.8.0

# Ollama Python Client (for PMCLLama via Ollama)
ollama>=0.1.0

